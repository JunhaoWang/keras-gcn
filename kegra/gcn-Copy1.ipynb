{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dropout, Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "import keras.backend as K\n",
    "from layers.graph import GraphConvolution\n",
    "from utils import *\n",
    "\n",
    "import time\n",
    "\n",
    "# Define parameters\n",
    "DATASET = 'cora'\n",
    "FILTER = 'localpool'  # 'chebyshev'\n",
    "MAX_DEGREE = 2  # maximum polynomial degree\n",
    "SYM_NORM = True  # symmetric (True) vs. left-only (False) normalization\n",
    "NB_EPOCH = 200\n",
    "PATIENCE = 10  # early stopping patience\n",
    "\n",
    "# Get data\n",
    "X, A, y = load_data(dataset=DATASET)\n",
    "y_train, y_val, y_test, idx_train, idx_val, idx_test, train_mask = get_splits(y)\n",
    "\n",
    "# Normalize X\n",
    "X /= X.sum(1).reshape(-1, 1)\n",
    "\n",
    "if FILTER == 'localpool':\n",
    "    \"\"\" Local pooling filters (see 'renormalization trick' in Kipf & Welling, arXiv 2016) \"\"\"\n",
    "    print('Using local pooling filters...')\n",
    "    A_ = preprocess_adj(A, SYM_NORM)\n",
    "    support = 1\n",
    "    graph = [X, A_]\n",
    "    G = [Input(shape=(None, None), batch_shape=(None, None), sparse=True)]\n",
    "\n",
    "elif FILTER == 'chebyshev':\n",
    "    \"\"\" Chebyshev polynomial basis filters (Defferard et al., NIPS 2016)  \"\"\"\n",
    "    print('Using Chebyshev polynomial basis filters...')\n",
    "    L = normalized_laplacian(A, SYM_NORM)\n",
    "    L_scaled = rescale_laplacian(L)\n",
    "    T_k = chebyshev_polynomial(L_scaled, MAX_DEGREE)\n",
    "    support = MAX_DEGREE + 1\n",
    "    graph = [X]+T_k\n",
    "    G = [Input(shape=(None, None), batch_shape=(None, None), sparse=True) for _ in range(support)]\n",
    "\n",
    "else:\n",
    "    raise Exception('Invalid filter type.')\n",
    "\n",
    "def convert_sparse_matrix_to_sparse_tensor(X):\n",
    "    coo = X.tocoo()\n",
    "    indices = np.mat([coo.row, coo.col]).transpose()\n",
    "    return tf.SparseTensor(indices, coo.data, coo.shape)\n",
    "\n",
    "class GAE(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(GAE, self).__init__()\n",
    "        self.conv1 = GraphConvolution(\n",
    "            16, 1, activation='relu', kernel_regularizer=l2(5e-4), name='conv1'\n",
    "        )\n",
    "        self.conv2 = GraphConvolution(\n",
    "            7, 1, activation='softmax', name='conv2'\n",
    "        )\n",
    "        self.dot = Lambda(lambda x: tf.reshape(K.dot(x, K.transpose(x)), [-1]), name='dot')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"Run the model.\"\"\"\n",
    "        X = tf.cast(tf.convert_to_tensor(inputs[0]), tf.double)\n",
    "        G = convert_sparse_matrix_to_sparse_tensor(inputs[1])\n",
    "        inputs_tensor = [X, G]\n",
    "        result = self.conv1(inputs_tensor)\n",
    "        result = self.conv2([result, G])\n",
    "        result = tf.squeeze(result, [0])\n",
    "        result = tf.reshape(self.dot(result), [-1])\n",
    "        return result\n",
    "\n",
    "    def encode(self, inputs):\n",
    "        X = inputs[0]\n",
    "        G = inputs[1]\n",
    "        inputs_tensor = [tf.cast(tf.convert_to_tensor(X), tf.double), G]\n",
    "        return tf.squeeze(self.conv2([self.conv1(inputs_tensor), G]))\n",
    "\n",
    "\n",
    "gae = GAE()\n",
    "\n",
    "gae(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " <2708x2708 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 13264 stored elements in Compressed Sparse Row format>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper variables for main training loop\n",
    "wait = 0\n",
    "preds = None\n",
    "best_val_loss = 99999\n",
    "\n",
    "# Fit\n",
    "for epoch in range(1, NB_EPOCH+1):\n",
    "\n",
    "    # Log wall-clock time\n",
    "    t = time.time()\n",
    "\n",
    "    # Single training iteration (we mask nodes without labels for loss calculation)\n",
    "    model.fit(graph, y_train, sample_weight=train_mask,\n",
    "              batch_size=A.shape[0], epochs=1, shuffle=False, verbose=0)\n",
    "\n",
    "    # Predict on full dataset\n",
    "    preds = model.predict(graph, batch_size=A.shape[0])\n",
    "\n",
    "    # Train / validation scores\n",
    "    train_val_loss, train_val_acc = evaluate_preds(preds, [y_train, y_val],\n",
    "                                                   [idx_train, idx_val])\n",
    "    print(\"Epoch: {:04d}\".format(epoch),\n",
    "          \"train_loss= {:.4f}\".format(train_val_loss[0]),\n",
    "          \"train_acc= {:.4f}\".format(train_val_acc[0]),\n",
    "          \"val_loss= {:.4f}\".format(train_val_loss[1]),\n",
    "          \"val_acc= {:.4f}\".format(train_val_acc[1]),\n",
    "          \"time= {:.4f}\".format(time.time() - t))\n",
    "\n",
    "    # Early stopping\n",
    "    if train_val_loss[1] < best_val_loss:\n",
    "        best_val_loss = train_val_loss[1]\n",
    "        wait = 0\n",
    "    else:\n",
    "        if wait >= PATIENCE:\n",
    "            print('Epoch {}: early stopping'.format(epoch))\n",
    "            break\n",
    "        wait += 1\n",
    "\n",
    "# Testing\n",
    "test_loss, test_acc = evaluate_preds(preds, [y_test], [idx_test])\n",
    "print(\"Test set results:\",\n",
    "      \"loss= {:.4f}\".format(test_loss[0]),\n",
    "      \"accuracy= {:.4f}\".format(test_acc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper variables for main training loop\n",
    "wait = 0\n",
    "preds = None\n",
    "best_val_loss = 99999\n",
    "\n",
    "# Fit\n",
    "for epoch in range(1, NB_EPOCH+1):\n",
    "\n",
    "    # Log wall-clock time\n",
    "    t = time.time()\n",
    "\n",
    "    # Single training iteration (we mask nodes without labels for loss calculation)\n",
    "    model.fit(graph, y_train, sample_weight=train_mask,\n",
    "              batch_size=A.shape[0], epochs=1, shuffle=False, verbose=0)\n",
    "\n",
    "    # Predict on full dataset\n",
    "    preds = model.predict(graph, batch_size=A.shape[0])\n",
    "\n",
    "    # Train / validation scores\n",
    "    train_val_loss, train_val_acc = evaluate_preds(preds, [y_train, y_val],\n",
    "                                                   [idx_train, idx_val])\n",
    "    print(\"Epoch: {:04d}\".format(epoch),\n",
    "          \"train_loss= {:.4f}\".format(train_val_loss[0]),\n",
    "          \"train_acc= {:.4f}\".format(train_val_acc[0]),\n",
    "          \"val_loss= {:.4f}\".format(train_val_loss[1]),\n",
    "          \"val_acc= {:.4f}\".format(train_val_acc[1]),\n",
    "          \"time= {:.4f}\".format(time.time() - t))\n",
    "\n",
    "    # Early stopping\n",
    "    if train_val_loss[1] < best_val_loss:\n",
    "        best_val_loss = train_val_loss[1]\n",
    "        wait = 0\n",
    "    else:\n",
    "        if wait >= PATIENCE:\n",
    "            print('Epoch {}: early stopping'.format(epoch))\n",
    "            break\n",
    "        wait += 1\n",
    "\n",
    "# Testing\n",
    "test_loss, test_acc = evaluate_preds(preds, [y_test], [idx_test])\n",
    "print(\"Test set results:\",\n",
    "      \"loss= {:.4f}\".format(test_loss[0]),\n",
    "      \"accuracy= {:.4f}\".format(test_acc[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
